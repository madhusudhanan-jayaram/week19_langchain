{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports and LLM loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ADVANCED RAG: COMPRESSION TECHNIQUE (Agent vs Non-Agent)\n",
    "# ============================================================================\n",
    "# This notebook compares:\n",
    "# 1. Basic RAG (no compression)\n",
    "# 2. RAG with Contextual Compression (without agent)\n",
    "# 3. Agentic RAG with Compression (with agent)\n",
    "\n",
    "# Compression = Filter/compress retrieved docs to only relevant parts\n",
    "# Agent = LLM decides retrieval strategy dynamically\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Compression imports\n",
    "from langchain_classic.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_classic.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "# Agent imports\n",
    "from langchain_classic.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_classic.tools.retriever import create_retriever_tool\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(\"✓ Imports and LLM loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 12 chunks into vector store\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Load Documents and Create Vector Store\n",
    "# ============================================================================\n",
    "\n",
    "loader = TextLoader(\"rag_test.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=chunks, embedding=embeddings)\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "print(f\"✓ Loaded {len(chunks)} chunks into vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Basic RAG chain created (no compression)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METHOD 1: BASIC RAG (No Compression) - BASELINE\n",
    "# ============================================================================\n",
    "# Simple retrieve → generate pipeline\n",
    "# Problem: Returns full chunks even if only a small part is relevant\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "basic_rag_chain = (\n",
    "    {\"context\": base_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | basic_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✓ Basic RAG chain created (no compression)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Compression RAG chain created (without agent)\n",
      "  - Uses LLMChainExtractor to compress retrieved docs\n",
      "  - Extracts only question-relevant content from each chunk\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METHOD 2: RAG WITH CONTEXTUAL COMPRESSION (Without Agent)\n",
    "# ============================================================================\n",
    "# Compression extracts ONLY the relevant parts from retrieved documents\n",
    "# \n",
    "# Flow:\n",
    "#   Question → Retrieve chunks → LLM Compressor extracts relevant parts → Generate\n",
    "#\n",
    "# Benefits:\n",
    "#   - Reduces noise in context\n",
    "#   - Saves tokens (cheaper)\n",
    "#   - More focused answers\n",
    "\n",
    "# Create compressor using LLM to extract relevant content\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# Wrap base retriever with compression\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "compression_rag_chain = (\n",
    "    {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | basic_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✓ Compression RAG chain created (without agent)\")\n",
    "print(\"  - Uses LLMChainExtractor to compress retrieved docs\")\n",
    "print(\"  - Extracts only question-relevant content from each chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agentic RAG created (with compression)\n",
      "  - Agent decides when to retrieve\n",
      "  - Can re-retrieve with different queries\n",
      "  - Self-correcting behavior\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METHOD 3: AGENTIC RAG WITH COMPRESSION (With Agent)\n",
    "# ============================================================================\n",
    "# Agent decides WHEN and HOW to retrieve\n",
    "#\n",
    "# Flow:\n",
    "#   Question → Agent thinks → Decides to use retrieval tool → \n",
    "#   Compressed retrieval → Agent analyzes → May retrieve again → Generate\n",
    "#\n",
    "# Benefits:\n",
    "#   - Can decide if retrieval is needed at all\n",
    "#   - Can re-retrieve with different queries\n",
    "#   - Can combine multiple retrieval strategies\n",
    "#   - Self-correcting behavior\n",
    "\n",
    "# Create retrieval tool with compression\n",
    "retriever_tool = create_retriever_tool(\n",
    "    compression_retriever,\n",
    "    name=\"lemobank_knowledge_base\",\n",
    "    description=\"Search for information about LemoBank products, policies, fees, and services. Use this tool when you need specific information about LemoBank.\"\n",
    ")\n",
    "\n",
    "# Agent prompt\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful LemoBank assistant. You have access to a knowledge base tool.\n",
    "\n",
    "RULES:\n",
    "1. ALWAYS use the knowledge base tool to find information before answering\n",
    "2. If the first search doesn't find relevant info, try rephrasing your search\n",
    "3. Only answer based on retrieved information\n",
    "4. If information is not found, say \"I don't have this information\"\n",
    "5. Cite your sources when possible\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# Create agent (using create_openai_tools_agent instead of deprecated functions_agent)\n",
    "agent = create_openai_tools_agent(llm, [retriever_tool], agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[retriever_tool], verbose=True)\n",
    "\n",
    "print(\"✓ Agentic RAG created (with compression)\")\n",
    "print(\"  - Agent decides when to retrieve\")\n",
    "print(\"  - Can re-retrieve with different queries\")\n",
    "print(\"  - Self-correcting behavior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUESTION: What is the latest LemoCard annual fee?\n",
      "================================================================================\n",
      "\n",
      "--- METHOD 1: BASIC RAG (No Compression) ---\n",
      "Answer: The latest LemoCard annual fee is ₹1,499, effective from 2025-11-15.\n",
      "\n",
      "--- METHOD 2: COMPRESSION RAG (Without Agent) ---\n",
      "Answer: The latest LemoCard annual fee is ₹1,499.\n",
      "\n",
      "--- METHOD 3: AGENTIC RAG (With Agent + Compression) ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `lemobank_knowledge_base` with `{'query': 'LemoCard annual fee'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m- LemoCard annual fee: ₹999\n",
      "- LemoCard annual fee increased to ₹1,499\n",
      "\n",
      "- “annual fee” may be phrased as “membership fee”\n",
      "\n",
      "Q3: What is the *latest* LemoCard annual fee?  \n",
      "Expected: ₹1,499 (effective 2025-11-15), not ₹999.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `lemobank_knowledge_base` with `{'query': 'latest LemoCard membership fee'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m- LemoCard annual fee increased to ₹1,499\n",
      "\n",
      "Q3: What is the *latest* LemoCard annual fee?  \n",
      "Expected: ₹1,499 (effective 2025-11-15), not ₹999.\u001b[0m\u001b[32;1m\u001b[1;3mThe latest LemoCard annual fee is ₹1,499, effective from November 15, 2025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: The latest LemoCard annual fee is ₹1,499, effective from November 15, 2025.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPARISON: Test All Three Methods\n",
    "# ============================================================================\n",
    "\n",
    "test_questions = [\n",
    "    \"What is the latest LemoCard annual fee?\",\n",
    "    \"Can I reverse a wallet transfer?\",\n",
    "    \"What is the refund timeline and what affects it?\",\n",
    "]\n",
    "\n",
    "def compare_methods(question):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Method 1: Basic RAG\n",
    "    print(\"\\n--- METHOD 1: BASIC RAG (No Compression) ---\")\n",
    "    basic_answer = basic_rag_chain.invoke(question)\n",
    "    print(f\"Answer: {basic_answer}\")\n",
    "    \n",
    "    # Method 2: Compression RAG\n",
    "    print(\"\\n--- METHOD 2: COMPRESSION RAG (Without Agent) ---\")\n",
    "    compression_answer = compression_rag_chain.invoke(question)\n",
    "    print(f\"Answer: {compression_answer}\")\n",
    "    \n",
    "    # Method 3: Agentic RAG\n",
    "    print(\"\\n--- METHOD 3: AGENTIC RAG (With Agent + Compression) ---\")\n",
    "    agent_answer = agent_executor.invoke({\"input\": question})\n",
    "    print(f\"Answer: {agent_answer['output']}\")\n",
    "\n",
    "# Run comparison for first question\n",
    "compare_methods(test_questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAW RETRIEVAL (No Compression)\n",
      "================================================================================\n",
      "\n",
      "[Chunk 1] (860 chars)\n",
      "[A2] Product Overview\n",
      "LemoBank has three products:\n",
      "1) LemoCard (credit card)\n",
      "   - Annual fee: ₹999\n",
      "   - Cashback: 1% on all spends\n",
      "2) LemoPay (UPI + wallet)\n",
      "   - Instant transfers within India\n",
      "3) LemoVault (savings)\n",
      "   - Base interest: 4% per annum\n",
      "   - Bonus interest: +1% per annum if monthly avera...\n",
      "\n",
      "[Chunk 2] (906 chars)\n",
      "Incident: INC-2025-12-20-002\n",
      "- Date: 2025-12-20\n",
      "- Service affected: LemoCard statement generation\n",
      "- Impact: statements for 1,200 users generated 1 day late\n",
      "- Root cause: batch job misconfigured cron\n",
      "- Status: Resolved\n",
      "\n",
      "[A9] FAQ (simple Q/A)\n",
      "Q: Can I change my registered phone number?\n",
      "A: Yes. It requ...\n",
      "\n",
      "[Chunk 3] (952 chars)\n",
      "[B5] Multi-hop (definition + threshold)\n",
      "Q5: Explain how monthly average balance is computed and why it matters for bonus interest.\n",
      "Expected: formula from [A13] + tie to bonus threshold.\n",
      "\n",
      "[B6] Table lookup\n",
      "Q6: Give the Bengaluru branch address.\n",
      "Expected: Indiranagar address from [A10].\n",
      "\n",
      "[B7] Synonyms...\n",
      "\n",
      "[Chunk 4] (925 chars)\n",
      "----------------------------------------------------------------------\n",
      "SECTION B — TEST QUERIES (run these against your RAG)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[B1] Simple retrieval\n",
      "Q1: What is LemoBank’s support email?\n",
      "Expected: support@lemobank.example\n",
      "\n",
      "[B2] Ba...\n",
      "\n",
      "================================================================================\n",
      "COMPRESSED RETRIEVAL\n",
      "================================================================================\n",
      "\n",
      "[Compressed 1] (41 chars)\n",
      "- LemoCard annual fee increased to ₹1,499\n",
      "\n",
      "[Compressed 2] (49 chars)\n",
      "- “annual fee” may be phrased as “membership fee”\n",
      "\n",
      "[Compressed 3] (50 chars)\n",
      "Expected: interpret as annual fee (₹1,499 latest).\n",
      "\n",
      "[Compressed 4] (98 chars)\n",
      "Q3: What is the *latest* LemoCard annual fee?  \n",
      "Expected: ₹1,499 (effective 2025-11-15), not ₹999.\n",
      "\n",
      "--- COMPRESSION STATS ---\n",
      "Raw total: 3643 chars\n",
      "Compressed total: 238 chars\n",
      "Compression ratio: 93.5% reduction\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE: What Compression Actually Does\n",
    "# ============================================================================\n",
    "# Let's see the difference between raw retrieval vs compressed retrieval\n",
    "\n",
    "question = \"What is the annual fee?\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RAW RETRIEVAL (No Compression)\")\n",
    "print(\"=\"*80)\n",
    "raw_docs = base_retriever.invoke(question)\n",
    "for i, doc in enumerate(raw_docs):\n",
    "    print(f\"\\n[Chunk {i+1}] ({len(doc.page_content)} chars)\")\n",
    "    print(doc.page_content[:300] + \"...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPRESSED RETRIEVAL\")\n",
    "print(\"=\"*80)\n",
    "compressed_docs = compression_retriever.invoke(question)\n",
    "for i, doc in enumerate(compressed_docs):\n",
    "    print(f\"\\n[Compressed {i+1}] ({len(doc.page_content)} chars)\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "# Calculate compression ratio\n",
    "raw_total = sum(len(d.page_content) for d in raw_docs)\n",
    "compressed_total = sum(len(d.page_content) for d in compressed_docs)\n",
    "print(f\"\\n--- COMPRESSION STATS ---\")\n",
    "print(f\"Raw total: {raw_total} chars\")\n",
    "print(f\"Compressed total: {compressed_total} chars\")\n",
    "print(f\"Compression ratio: {(1 - compressed_total/raw_total)*100:.1f}% reduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AGENT BEHAVIOR: Watch the Agent Think\n",
    "# ============================================================================\n",
    "# The agent can:\n",
    "# 1. Decide if retrieval is needed\n",
    "# 2. Rephrase queries if first search fails\n",
    "# 3. Make multiple searches for complex questions\n",
    "\n",
    "# Complex question that might need multiple retrievals\n",
    "complex_question = \"Compare the old and new annual fees, and explain the refund policy\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AGENTIC RAG: Complex Multi-Part Question\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Question: {complex_question}\\n\")\n",
    "\n",
    "# verbose=True shows agent's thinking process\n",
    "result = agent_executor.invoke({\"input\": complex_question})\n",
    "print(f\"\\nFINAL ANSWER: {result['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                    RAG COMPRESSION: AGENT VS NON-AGENT                       ║\n",
      "╠══════════════════════════════════════════════════════════════════════════════╣\n",
      "║                                                                              ║\n",
      "║  METHOD 1: BASIC RAG (No Compression)                                        ║\n",
      "║  ├─ Flow: Question → Retrieve → Generate                                     ║\n",
      "║  ├─ Pros: Fast, simple, low cost                                             ║\n",
      "║  ├─ Cons: Full chunks (noisy), may exceed context limits                     ║\n",
      "║  └─ Use when: Simple questions, small chunks, cost-sensitive                 ║\n",
      "║                                                                              ║\n",
      "║  METHOD 2: COMPRESSION RAG (Without Agent)                                   ║\n",
      "║  ├─ Flow: Question → Retrieve → Compress → Generate                          ║\n",
      "║  ├─ Pros: Focused context, saves tokens, better answers                      ║\n",
      "║  ├─ Cons: Extra LLM call for compression, slightly slower                    ║\n",
      "║  └─ Use when: Large chunks, need precise answers, have noisy docs            ║\n",
      "║                                                                              ║\n",
      "║  METHOD 3: AGENTIC RAG (With Agent + Compression)                            ║\n",
      "║  ├─ Flow: Question → Agent decides → Retrieve → Compress → Analyze → ...     ║\n",
      "║  ├─ Pros: Self-correcting, handles complex questions, can re-retrieve        ║\n",
      "║  ├─ Cons: Slower, more expensive, unpredictable # of LLM calls               ║\n",
      "║  └─ Use when: Complex multi-part questions, need reliability over speed      ║\n",
      "║                                                                              ║\n",
      "╠══════════════════════════════════════════════════════════════════════════════╣\n",
      "║                           COMPARISON TABLE                                   ║\n",
      "╠═══════════════════╦═══════════════╦═══════════════════╦══════════════════════╣\n",
      "║ Feature           ║ Basic RAG     ║ Compression RAG   ║ Agentic RAG          ║\n",
      "╠═══════════════════╬═══════════════╬═══════════════════╬══════════════════════╣\n",
      "║ LLM Calls         ║ 1             ║ 2 (compress+gen)  ║ 2-5+ (varies)        ║\n",
      "║ Latency           ║ Fast          ║ Medium            ║ Slow                 ║\n",
      "║ Cost              ║ Low           ║ Medium            ║ High                 ║\n",
      "║ Context Quality   ║ Noisy         ║ Focused           ║ Focused              ║\n",
      "║ Self-Correction   ║ No            ║ No                ║ Yes                  ║\n",
      "║ Multi-hop         ║ No            ║ No                ║ Yes                  ║\n",
      "║ Query Rewriting   ║ No            ║ No                ║ Yes                  ║\n",
      "╚═══════════════════╩═══════════════╩═══════════════════╩══════════════════════╝\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SUMMARY: When to Use Each Method\n",
    "# ============================================================================\n",
    "\n",
    "summary = \"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    RAG COMPRESSION: AGENT VS NON-AGENT                       ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  METHOD 1: BASIC RAG (No Compression)                                        ║\n",
    "║  ├─ Flow: Question → Retrieve → Generate                                     ║\n",
    "║  ├─ Pros: Fast, simple, low cost                                             ║\n",
    "║  ├─ Cons: Full chunks (noisy), may exceed context limits                     ║\n",
    "║  └─ Use when: Simple questions, small chunks, cost-sensitive                 ║\n",
    "║                                                                              ║\n",
    "║  METHOD 2: COMPRESSION RAG (Without Agent)                                   ║\n",
    "║  ├─ Flow: Question → Retrieve → Compress → Generate                          ║\n",
    "║  ├─ Pros: Focused context, saves tokens, better answers                      ║\n",
    "║  ├─ Cons: Extra LLM call for compression, slightly slower                    ║\n",
    "║  └─ Use when: Large chunks, need precise answers, have noisy docs            ║\n",
    "║                                                                              ║\n",
    "║  METHOD 3: AGENTIC RAG (With Agent + Compression)                            ║\n",
    "║  ├─ Flow: Question → Agent decides → Retrieve → Compress → Analyze → ...     ║\n",
    "║  ├─ Pros: Self-correcting, handles complex questions, can re-retrieve        ║\n",
    "║  ├─ Cons: Slower, more expensive, unpredictable # of LLM calls               ║\n",
    "║  └─ Use when: Complex multi-part questions, need reliability over speed      ║\n",
    "║                                                                              ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                           COMPARISON TABLE                                   ║\n",
    "╠═══════════════════╦═══════════════╦═══════════════════╦══════════════════════╣\n",
    "║ Feature           ║ Basic RAG     ║ Compression RAG   ║ Agentic RAG          ║\n",
    "╠═══════════════════╬═══════════════╬═══════════════════╬══════════════════════╣\n",
    "║ LLM Calls         ║ 1             ║ 2 (compress+gen)  ║ 2-5+ (varies)        ║\n",
    "║ Latency           ║ Fast          ║ Medium            ║ Slow                 ║\n",
    "║ Cost              ║ Low           ║ Medium            ║ High                 ║\n",
    "║ Context Quality   ║ Noisy         ║ Focused           ║ Focused              ║\n",
    "║ Self-Correction   ║ No            ║ No                ║ Yes                  ║\n",
    "║ Multi-hop         ║ No            ║ No                ║ Yes                  ║\n",
    "║ Query Rewriting   ║ No            ║ No                ║ Yes                  ║\n",
    "╚═══════════════════╩═══════════════╩═══════════════════╩══════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
