{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f42c062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded: AIzaSy...\n",
      "OpenAI Key loaded: sk-pro...\n",
      "Tavily Key loaded: tvly-d...\n",
      "Gemini response: content='Here are some creative names for a smart home device company, broken down by theme to inspire you:\\n\\n## Evocative & Modern\\n\\nThese names aim for a sense of wonder, sophistication, and futuristic living.\\n\\n1.  **AuraLogic:** Combines the ethereal \"aura\" with the practical \"logic\" of smart tech.\\n2.  **Synapse Living:** Evokes the neural connections of the brain, suggesting an interconnected, intelligent home.\\n3.  **Veridian Home:** \"Veridian\" suggests lushness, growth, and a thriving, intelligent environment.\\n4.  **Zenith Dwell:** \"Zenith\" implies the peak or highest point of living, while \"Dwell\" is a classic term for home.\\n5.  **LumenFlow:** \"Lumen\" (light) for clarity and vision, \"Flow\" for seamless operation and energy.\\n6.  **EchoSphere:** Suggests responsiveness, an enveloping environment, and a cohesive system.\\n7.  **CogniHab:** A blend of \"Cognitive\" (smart, thinking) and \"Habitat\" (home).\\n8.  **Orchestra Home:** Implies all devices working in perfect harmony, directed by a central intelligence.\\n9.  **HarmoniQ:** A modern take on \"harmony\" with a tech-forward \\'Q\\' or \\'K\\'.\\n10. **Fluxion Living:** \"Fluxion\" suggests constant change, flow, and dynamism, implying adaptability and innovation.\\n\\n## Simple & Catchy\\n\\nEasy to remember, pronounce, and brand.\\n\\n11. **Alloy Living:** \"Alloy\" suggests strength, integration, and a blend of components.\\n12. **Kinetic Home:** Implies movement, responsiveness, and an active, adaptive living space.\\n13. **Vivid Tech:** Suggests clear, vibrant experiences and cutting-edge technology.\\n14. **Kore Systems:** \"Kore\" (core) implies centrality, foundation, and essential intelligence.\\n15. **Linkwell:** Straightforward, indicating connectivity and wellness in the home.\\n16. **Ondus:** A unique, soft-sounding name suggesting waves, flow, or a calming presence.\\n17. **Zylos:** A short, punchy, and modern-sounding name.\\n18. **HomeOS:** Clearly positions the company as providing the \"operating system\" for your home.\\n19. **Nexus Home:** \"Nexus\" means a central link or connection point.\\n20. **ArchiSmart:** Combines architecture with smart technology, hinting at integrated design.\\n\\n## Playful & Creative\\n\\nNames that are a bit more whimsical or use clever wordplay.\\n\\n21. **The Smart Hearth:** A classic symbol of home (hearth) with a modern twist.\\n22. **Abode Alchemist:** Positions your company as transforming homes into something magical.\\n23. **Domestic Genii:** \"Genii\" (plural of genius, or a spirit/djinn) suggests intelligent assistants for the home.\\n24. **Curio Dwell:** \"Curio\" suggests interesting, unique, and clever devices for the home.\\n25. **Wizdom Living:** A playful blend of \"wizardry\" and \"wisdom\" for smart solutions.\\n\\n## Tips for Choosing:\\n\\n*   **Check Domain Availability:** Is `.com` (and other relevant TLDs) available?\\n*   **Social Media Handles:** Can you get consistent handles across platforms?\\n*   **Trademark Search:** Crucial to avoid legal issues later on.\\n*   **Pronunciation & Spelling:** Is it easy to say and spell?\\n*   **Memorability:** Will people remember it after hearing it once?\\n*   **Brand Fit:** Does the name convey the values and feel of your company? (e.g., sophisticated, playful, practical).\\n*   **Scalability:** Does the name allow for future expansion beyond just smart home devices, if desired?\\n\\nGood luck!' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b4b58-1262-70e2-8008-0402daa3aa12-0' usage_metadata={'input_tokens': 15, 'output_tokens': 2308, 'total_tokens': 2323, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1457}}\n",
      "OpenAI response: content='\"IntelliHome Innovations\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 21, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CpwV3MCQzRQgVValHX9L4oWQGRwWt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b4b58-4c98-7302-8ea0-d52b4292eff6-0' usage_metadata={'input_tokens': 21, 'output_tokens': 7, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "assert GEMINI_API_KEY, \"GEMINI_API_KEY is missing. Check your .env file.\"\n",
    "assert OPENAI_API_KEY, \"OPENAI_API_KEY is missing. Check your .env file.\"\n",
    "assert TAVILY_API_KEY, \"TAVILY_API_KEY is missing. Check your .env file.\"\n",
    "\n",
    "print(\"Key loaded:\", GEMINI_API_KEY[:6] + \"...\" )\n",
    "print(\"OpenAI Key loaded:\", OPENAI_API_KEY[:6] + \"...\")\n",
    "print(\"Tavily Key loaded:\", TAVILY_API_KEY[:6] + \"...\")\n",
    "\n",
    "# Initialize LLMs\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0,\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=GEMINI_API_KEY\n",
    ")\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"Give me a creative name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "# Example: Use Gemini\n",
    "chain = prompt | gemini_llm\n",
    "response = chain.invoke({\"product\": \"smart home devices\"})\n",
    "print(\"Gemini response:\", response)\n",
    "\n",
    "# Example: Use OpenAI\n",
    "chain = prompt | openai_llm\n",
    "response = chain.invoke({\"product\": \"smart home devices\"})\n",
    "print(\"OpenAI response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e37a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_idea_tool result: content='MindFit Technologies' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 22, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CpwV4P3RJI7VSV1AiW3SgTGgmY4dq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b4b58-5003-7322-9b8a-9ae8eb928676-0' usage_metadata={'input_tokens': 22, 'output_tokens': 3, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Wrap LLM chain (PromptTemplate -> OpenAI) as a tool\n",
    "\n",
    "# Reuse existing prompt and LLM (or switch to openai_llm2 if you prefer limits)\n",
    "name_idea_chain = prompt | openai_llm\n",
    "\n",
    "# Turn the chain into a tool\n",
    "name_idea_tool = name_idea_chain.as_tool(\n",
    "    name=\"name_idea_tool\",\n",
    "    description=\"Given a product description, generate a creative company name.\"\n",
    ")\n",
    "\n",
    "# Test the tool directly\n",
    "tool_result = name_idea_tool.invoke({\"product\": \"AI fitness wearables\"})\n",
    "print(\"name_idea_tool result:\", tool_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e473906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOOL .invoke() ===\n",
      "content='I apologize for the inconvenience you experienced with your recent order. We strive to deliver food promptly and ensure it arrives hot. I will escalate this issue to our operations team to investigate and improve our service in your area. Priority: High.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 77, 'total_tokens': 124, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CpwV4NsuqhFv9WWDZMICQKmGbnK3J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b4b58-5366-7970-bd9c-13037d34e0a8-0' usage_metadata={'input_tokens': 77, 'output_tokens': 47, 'total_tokens': 124, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "support_prompt = PromptTemplate(\n",
    "    input_variables=[\"issue\"],\n",
    "    template=(\n",
    "        \"You are a customer support agent for a food delivery app.\\n\"\n",
    "        \"Customer issue:\\n\\\"\\\"\\\"{issue}\\\"\\\"\\\"\\n\\n\"\n",
    "        \"1) Write a short, polite reply (3–4 sentences).\\n\"\n",
    "        \"2) At the end, add: Priority: Low / Medium / High.\\n\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Chain: prompt -> OpenAI LLM\n",
    "support_chain = support_prompt | openai_llm\n",
    "\n",
    "# Wrap the chain as a tool\n",
    "support_tool = support_chain.as_tool(\n",
    "    name=\"support_reply\",\n",
    "    description=\"Given a customer issue, draft a reply and assign a priority.\"\n",
    ")\n",
    "\n",
    "# ---- Run the chain directly with invoke (recommended) ----\n",
    "issue_text = (\n",
    "    \"My order arrived 45 minutes late and the food was already cold. \"\n",
    "    \"This keeps happening with your service in my area.\"\n",
    ")\n",
    "\n",
    "# ---- Run the wrapped tool (tools always take a dict) ----\n",
    "print(\"\\n=== TOOL .invoke() ===\")\n",
    "tool_result = support_tool.invoke({\"issue\": issue_text})\n",
    "print(tool_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21948d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== fahrenheit_to_celsius tool ===\n",
      "30.0\n",
      "\n",
      "=== max_hotel_nights tool ===\n",
      "6\n",
      "\n",
      "=== city_guide_tool (LLM chain as tool) ===\n",
      "content='Must-see places:\\n- Visit the historic Senso-ji Temple in Asakusa\\n- Explore the bustling streets of Shibuya and cross the famous Shibuya Crossing\\n- Take a stroll through the beautiful gardens of the Imperial Palace\\n\\nFood suggestions:\\n- Try some delicious sushi at the Tsukiji Fish Market\\n- Indulge in a bowl of authentic ramen at Ichiran Ramen\\n- Sample some traditional Japanese street food at the Tsukiji Outer Market' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 39, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CpwV5NFmiHdd02Du2jmaOJYrKE6DF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b4b58-55d3-7070-b679-7de98f1c7003-0' usage_metadata={'input_tokens': 39, 'output_tokens': 95, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "=== assistant_with_travel_tools.invoke(...) ===\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 187, 'total_tokens': 267, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CpwV5YoToBFoorAheAnOAUnq8urwB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019b4b58-58ed-7ad3-92f3-eb2d563ce8b3-0' tool_calls=[{'name': 'max_hotel_nights', 'args': {'budget_usd': 800, 'price_per_night_usd': 120}, 'id': 'call_hTVBJGL40IfiEpi0D3WNX1O7', 'type': 'tool_call'}, {'name': 'city_guide', 'args': {'city': 'Tokyo', 'days': '4'}, 'id': 'call_moglzkLJIQ8J0OakJtHPNBDH', 'type': 'tool_call'}, {'name': 'fahrenheit_to_celsius', 'args': {'fahrenheit': 86}, 'id': 'call_t8uc8MTNCPMS5c7tGi81ZI4L', 'type': 'tool_call'}] usage_metadata={'input_tokens': 187, 'output_tokens': 80, 'total_tokens': 267, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ---------- 1) Define function tools ----------\n",
    "\n",
    "@tool\n",
    "def fahrenheit_to_celsius(fahrenheit: float) -> float:\n",
    "    \"\"\"Convert temperature in Fahrenheit to Celsius.\"\"\"\n",
    "    return round((fahrenheit - 32) * 5 / 9, 1)\n",
    "\n",
    "\n",
    "@tool\n",
    "def max_hotel_nights(budget_usd: float, price_per_night_usd: float) -> int:\n",
    "    \"\"\"Given a budget and price per night, return how many full nights you can afford.\"\"\"\n",
    "    if price_per_night_usd <= 0:\n",
    "        raise ValueError(\"price_per_night_usd must be > 0\")\n",
    "    return int(budget_usd // price_per_night_usd)\n",
    "\n",
    "\n",
    "# ---------- 2) LLM chain wrapped as a tool ----------\n",
    "\n",
    "city_guide_prompt = PromptTemplate(\n",
    "    input_variables=[\"city\", \"days\"],\n",
    "    template=(\n",
    "        \"You are a friendly local guide.\\n\"\n",
    "        \"The user will visit {city} for {days} days.\\n\"\n",
    "        \"Give 3 concise bullet points with must‑see places and food suggestions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "city_guide_chain = city_guide_prompt | openai_llm\n",
    "\n",
    "city_guide_tool = city_guide_chain.as_tool(\n",
    "    name=\"city_guide\",\n",
    "    description=\"Given a city and number of days, suggest must‑see places and food.\"\n",
    ")\n",
    "\n",
    "# ---------- 3) Use each tool directly with .invoke() ----------\n",
    "\n",
    "print(\"=== fahrenheit_to_celsius tool ===\")\n",
    "print(\n",
    "    fahrenheit_to_celsius.invoke({\"fahrenheit\": 86})\n",
    ")\n",
    "\n",
    "print(\"\\n=== max_hotel_nights tool ===\")\n",
    "print(\n",
    "    max_hotel_nights.invoke({\"budget_usd\": 800, \"price_per_night_usd\": 120})\n",
    ")\n",
    "\n",
    "print(\"\\n=== city_guide_tool (LLM chain as tool) ===\")\n",
    "print(\n",
    "    city_guide_tool.invoke({\"city\": \"Tokyo\", \"days\": \"4\"})\n",
    ")\n",
    "\n",
    "# ---------- 4) Bind MULTIPLE tools to the LLM, then .invoke() ----------\n",
    "\n",
    "travel_tools = [fahrenheit_to_celsius, max_hotel_nights, city_guide_tool]\n",
    "\n",
    "assistant_with_travel_tools = openai_llm.bind_tools(travel_tools)\n",
    "\n",
    "user_query = (\n",
    "    \"I'm planning a 4‑day trip to Tokyo with a hotel budget of 800 USD and \"\n",
    "    \"average price 120 USD per night. \"\n",
    "    \"How many nights can I afford, and give me local tips. \"\n",
    "    \"Also, if it's 86 F there, what is that in Celsius?\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== assistant_with_travel_tools.invoke(...) ===\")\n",
    "response = assistant_with_travel_tools.invoke(user_query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
