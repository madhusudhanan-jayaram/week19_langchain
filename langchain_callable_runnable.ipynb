{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb4bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded: AIzaSy...\n",
      "OpenAI Key loaded: sk-pro...\n",
      "Tavily Key loaded: tvly-d...\n",
      "Gemini response: content='Okay, here are some creative names for a smart home device company, categorized by the feeling or concept they evoke:\\n\\n**Modern & Tech-Forward:**\\n\\n1.  **AuraSync:** Evokes a feeling of seamless, intelligent harmony.\\n2.  **LumenHaus:** \"Lumen\" (light/illumination) + \"Haus\" (German for home). Sounds sleek and intelligent.\\n3.  **CoreLogic Living:** Suggests an intelligent central system at the heart of the home.\\n4.  **NexHome:** Short for \"Next Home\" or \"Nexus Home,\" implying a central connection point.\\n5.  **Veridian Systems:** \"Veridian\" suggests green, fresh, and maybe even future-focused tech.\\n6.  **KinetiHome:** From \"kinetic,\" implying movement, automation, and responsiveness.\\n7.  **OptiLive:** Optimizing your living experience.\\n8.  **Synthetica Home:** Suggests a crafted, integrated, and smart environment.\\n9.  **Zenith Automation:** \"Zenith\" implies the peak or highest point of achievement.\\n10. **EvrSense:** \"Ever sense,\" implying constant awareness and responsiveness.\\n\\n**Comfort & Lifestyle Focused:**\\n\\n11. **AbodeWell:** Simple, elegant, focusing on a better quality of life at home.\\n12. **HearthFlow:** Combines the warmth of \"hearth\" with the seamless \"flow\" of automation.\\n13. **HavenEase:** Your home as a haven, made effortless.\\n14. **SereneLife Tech:** Emphasizes peace, calm, and an easy lifestyle.\\n15. **Bloom Living:** Suggests a home that\\'s alive, growing, and thriving with intelligence.\\n16. **EchoNest:** A cozy, responsive home that understands and adapts.\\n17. **VitaFlow:** \"Vita\" (life) combined with effortless \"flow.\"\\n18. **Glimpse Home:** A subtle nod to intelligent insights and foresight in your home.\\n19. **Solstice Living:** Evokes balance, comfort, and the turning points of your day.\\n20. **NestWeave:** Suggests intricately connected systems creating a comfortable home.\\n\\n**Evocative & Abstract:**\\n\\n21. **The Gridwell:** A subtle, powerful name hinting at an intelligent network.\\n22. **Prism Living:** Suggests clarity, light, and a multifaceted approach to smart living.\\n23. **Conduit Connect:** Emphasizes seamless pathways and integration.\\n24. **Ember Systems:** Evokes warmth, a subtle glow, and a core, enduring presence.\\n25. **TerraNova Home:** \"New Earth\" or \"New Home,\" hinting at innovative possibilities.\\n26. **Verve Home:** \"Verve\" means enthusiasm or vigor, suggesting a lively, responsive home.\\n27. **Rhythm AI:** Your home moving in sync with your life.\\n28. **Arbor Sense:** \"Arbor\" (tree, shelter) combined with intelligence – a natural, protective feel.\\n29. **ChromaHome:** Evokes color, vibrancy, and personalized atmosphere.\\n30. **Locus Living:** \"Locus\" means a particular position or place, highlighting the home as a central intelligent point.\\n\\n**Tips for Choosing:**\\n\\n*   **Check Domain Availability:** Is the .com (or relevant TLD) available?\\n*   **Social Media Handles:** Can you get consistent handles across platforms?\\n*   **Memorability & Pronunciation:** Is it easy to say, spell, and remember?\\n*   **Brand Messaging:** Does the name align with the overall message and values of your company?\\n*   **Avoid Conflicts:** Research existing trademarks in your industry.\\n\\nGood luck!' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b550e-7186-72e0-aeb3-4763bf53474f-0' usage_metadata={'input_tokens': 15, 'output_tokens': 2423, 'total_tokens': 2438, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1610}}\n",
      "OpenAI response: content='IntelliHome Technologies' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 21, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CqctD3eY9TY2FSn0vSBvQqgzgK0ol', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b550e-a7a0-7e30-9745-cc0d21b86310-0' usage_metadata={'input_tokens': 21, 'output_tokens': 4, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "assert GEMINI_API_KEY, \"GEMINI_API_KEY is missing. Check your .env file.\"\n",
    "assert OPENAI_API_KEY, \"OPENAI_API_KEY is missing. Check your .env file.\"\n",
    "assert TAVILY_API_KEY, \"TAVILY_API_KEY is missing. Check your .env file.\"\n",
    "\n",
    "print(\"Key loaded:\", GEMINI_API_KEY[:6] + \"...\" )\n",
    "print(\"OpenAI Key loaded:\", OPENAI_API_KEY[:6] + \"...\")\n",
    "print(\"Tavily Key loaded:\", TAVILY_API_KEY[:6] + \"...\")\n",
    "\n",
    "# Initialize LLMs\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0,\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=GEMINI_API_KEY\n",
    ")\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"Give me a creative name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "# Example: Use Gemini\n",
    "chain = prompt | gemini_llm\n",
    "response = chain.invoke({\"product\": \"smart home devices\"})\n",
    "print(\"Gemini response:\", response)\n",
    "\n",
    "# Example: Use OpenAI\n",
    "chain = prompt | openai_llm\n",
    "response = chain.invoke({\"product\": \"smart home devices\"})\n",
    "print(\"OpenAI response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaddd3b",
   "metadata": {},
   "source": [
    "# RunnableLambda\n",
    "\n",
    "### RunnableLambda = “Take input → run my function → return output”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8a89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO!!!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# A normal Python function\n",
    "def shout(text):\n",
    "    return text.upper() + \"!!!\"\n",
    "\n",
    "# Convert it into a Runnable\n",
    "shout_runnable = RunnableLambda(shout)\n",
    "\n",
    "# Run it\n",
    "output = shout_runnable.invoke(\"hello\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50f489",
   "metadata": {},
   "source": [
    "# RunnableParallel\n",
    "\n",
    "### RunnableParallel – “Do many things at the same time”\n",
    "\n",
    "### RunnableParallel = “Same input → many branches → merge results”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ac6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'langchain', 'upper': 'LANGCHAIN', 'length': 9}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    \"original\": RunnableLambda(lambda x: x),\n",
    "    \"upper\": RunnableLambda(lambda x: x.upper()),\n",
    "    \"length\": RunnableLambda(lambda x: len(x))\n",
    "})\n",
    "\n",
    "result = parallel.invoke(\"langchain\")\n",
    "print(result)\n",
    "\n",
    "#RunnableLambda       → run custom Python logic\n",
    "# RunnablePassthrough  → keep input unchanged\n",
    "#RunnableParallel     → run many things in parallel\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
